name: Local Measurement of Ollama in Docker
author: Bennet Wilhelm <bennet.wilhelm@accso.de>, Kollin Freise <kollin.freise@accso.de>
description: WIP. Measuring the energy consumption of Ollama running in Docker

services:
  ollama-in-docker:
    image: ollama/ollama:latest
    container_name: ollama-in-docker
    "folder-destination": "/tmp/greenkiollamamesurements"
    setup-commands:
      - command: mkdir /var/greenkiollamamesurements
      - command: cp /tmp/greenkiollamamesurements/warmup.sh /var/greenkiollamamesurements/warmup.sh
      - command: chmod +x /var/greenkiollamamesurements/warmup.sh
      - command: cp /tmp/greenkiollamamesurements/runScript.sh /var/greenkiollamamesurements/runScript.sh
      - command: chmod +x /var/greenkiollamamesurements/runScript.sh
    "docker-run-args": 
      - "--gpus=all"

flow:
  - name: Download model
    container: ollama-in-docker
    commands:
      - type: console
        command: ollama pull codellama:7b
        note: Downloading model
  - name: Start Ollama and warm-up models
    container: ollama-in-docker
    commands:
      - type: console
        command: sh /var/greenkiollamamesurements/warmup.sh codellama:7b
        note: Warming up model
  - name: Running model with programming tasks
    container: ollama-in-docker
    commands:
      - type: console
        command: sh /var/greenkiollamamesurements/runScript.sh codellama:7b
        note: Test model
